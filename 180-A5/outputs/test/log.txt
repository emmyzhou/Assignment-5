Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
Training/evaluation parameters Namespace(adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./test', device=device(type='cpu'), do_eval=False, do_lower_case=False, do_predict=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, load_weak=False, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='roberta-base', model_type='roberta', mt=0, mt_alpha1=0.99, mt_alpha2=0.995, mt_avg='exponential', mt_beta=10, mt_class='kl', mt_lambda=1, mt_loss_type='logits', mt_rampup=300, mt_updatefreq=1, n_gpu=0, no_cuda=False, num_train_epochs=3.0, output_dir='./outputs/test', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, remove_labels_from_weak=False, rep_train_against_weak=1, save_steps=50, seed=42, server_ip='', server_port='', test='test', tokenizer_name='', vat=0, vat_beta=1, vat_eps=0.001, vat_lambda=1, vat_loss_type='logits', warmup_steps=0, weight_decay=0.0)
Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
Training/evaluation parameters Namespace(adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./test', device=device(type='cpu'), do_eval=False, do_lower_case=False, do_predict=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, load_weak=False, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='roberta-base', model_type='roberta', mt=0, mt_alpha1=0.99, mt_alpha2=0.995, mt_avg='exponential', mt_beta=10, mt_class='kl', mt_lambda=1, mt_loss_type='logits', mt_rampup=300, mt_updatefreq=1, n_gpu=0, no_cuda=False, num_train_epochs=3.0, output_dir='./outputs/test', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, remove_labels_from_weak=False, rep_train_against_weak=1, save_steps=50, seed=42, server_ip='', server_port='', test='test', tokenizer_name='', vat=0, vat_beta=1, vat_eps=0.001, vat_lambda=1, vat_loss_type='logits', warmup_steps=0, weight_decay=0.0)
Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False
Training/evaluation parameters Namespace(adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./test', device=device(type='cpu'), do_eval=False, do_lower_case=False, do_predict=False, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, load_weak=False, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='roberta-base', model_type='roberta', mt=0, mt_alpha1=0.99, mt_alpha2=0.995, mt_avg='exponential', mt_beta=10, mt_class='kl', mt_lambda=1, mt_loss_type='logits', mt_rampup=300, mt_updatefreq=1, n_gpu=0, no_cuda=False, num_train_epochs=3.0, output_dir='./outputs/test', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, remove_labels_from_weak=False, rep_train_against_weak=1, save_steps=50, seed=42, server_ip='', server_port='', test='test', tokenizer_name='', vat=0, vat_beta=1, vat_eps=0.001, vat_lambda=1, vat_loss_type='logits', warmup_steps=0, weight_decay=0.0)
